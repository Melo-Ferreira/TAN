---
title: "Modelagem TAN"
author: "Vanessa Melo"
date: "Março de 2020"
output: word_document
---

```{r , include = FALSE}
setwd('E:\\Artigo TAN\\ANÁLISES 2020') 
```

```{r , echo = TRUE}
load('TAN.rda') #Carregando o banco
```

```{r, include = FALSE}
library(lme4)
library(car)
library(DHARMa)
```


## Matriz de correlação de Pearson: Colinearidade das variáveis numéricas
```{r , echo = F}
matriz=subset(criamae,select=c(p_ext_pobres,p_pobres,idmh_renda,idmh_longevidade,idmh_educacao,
                                  c7,ct,cnt,pomif,poinf,
                                  taxami,taxasc))
matrizCOR=cor(matriz,method=c("pearson"))                                
matrizCOR=round(matrizCOR,2)
```

```{r , echo = T}
matrizCOR
##Resultados acima de 0,6 ou -0,6.
#p_ext_pobres=> p_pobres
#p_pobres=> p_ext_pobres,idmh_renda,idmh_longevidade,c7
#idmh_renda=> p_pobres,idmh_longevidade,c7
#idmh_longevidade=> p_pobres,idmh_renda,idmh_educacao,c7
#idmh_educacao=> idmh_renda,idmh_longevidade,c7
#c7=> idmh_renda,idmh_longevidade,idmh_educacao
#pomif=> poinf

# Portanto será refeita a análise da matriz de correlação de Pearson sem as variáveis que se mostraram colineares

# Escolhas:
#p_ext_pobres=> por carregar a informação de p_pobres
#c7=> por representar bem idmh_renda,idmh_longevidade,idmh_educacao e ao mesmo tempo não ser colinear do indicadro de pobreza
#pomif=> Será escolhido em detrimento de poinf porque no contraste com as demais variáveis da matriz de correlação, pomif foi menos colinear!

#Serão excluídos:
#p_pobres,idmh_renda,idmh_longevidade,idmh_educacao,
#poinf
```

## Nova matriz de correlação com as variáveis escolhidas
```{r , echo = F}
matriz=subset(criamae,select=c(p_ext_pobres,c7,ct,cnt,pomif,taxami,taxasc))
matrizCOR=cor(matriz,method=c("pearson"))                                
matrizCOR=round(matrizCOR,2)
```

```{r , echo = T}
matrizCOR
```

```{r , echo = T}
#Após isso, as variáveis contextuais foram centradas na média:

#p_ext_pobres_c
#c7_c
#ct_c
#cnt_c
#pomif_c
#taxami_c
#taxasc_c
```

## Modelos Predisponentes

# Predisponentes sem pesos
```{r , echo = F}
m1SemPesos=glmer(tan~p_ext_pobres_c +
            idade_mae +racacor_mae +compx +educ_mae +partos_mae +
            (1|capitais),family=binomial(link = logit),data=criamae)
summary(m1SemPesos)
```


```{r , echo = F}
#Calculos do intervalo de confiança predisponentes sem pesos
dados=as.data.frame(coef(summary(m1SemPesos)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)

dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança predisponentes sem pesos
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF):Predisponentes sem pesos - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m1SemPesos),3) # OK, VIFS menores que 5!
```

# Diagnóstico de modelos (comparação entre modelos aninhados): Predisponentes sem pesos
```{r , echo = F}
#Modelo vazio
m0SemPesos=glmer(tan~(1|capitais),family=binomial(link = logit),data=criamae)
summary(m0SemPesos)

logLik(m0SemPesos)
#Modelo com variáveis
logLik(m1SemPesos)
```

```{r , echo = T}
lv= -291.3673       #logLik do modelo vazio
lc= -272.7958       #logLik do modelo cheio
l=-2*(lv-lc)      #Estatística do teste l
p=  6            # numero de variáveis do cheio
q= 0             #número de variáveis do vazio
a=0.05            #nível de significância
gl=p-q            # graus de liberdade
vc=qchisq(1-a,gl) # distribuição qui-quadrado
pvalor=pchisq(l,gl,lower.tail=F)
testerv=c("Estatística l"=l,"Valor crítico:Qui-quadrado (p-q)graus de liberdade"=vc) 
```

```{r , echo = T}
c(round((testerv),2) , "p-valor" =round((pvalor),3))
# Foi significativo. Portanto, rejeita-se a H0 de que todos os coeficientes das variáveis explicativas que estão presentes APENAS no modelo cheio sejam iguais a ZERO!
```

# Diagnóstico de resíduos: Predisponentes sem pesos
```{r , echo = T}
# Criando resíduos redimensionados com alta precisão
simulationOutput <- simulateResiduals(fittedModel = m1SemPesos, n = 1000)

# Guardando os rediduos obtidos: Como discutido acima, para um modelo especificado corretamente, esperaríamos uma distribuição uniforme (plana) dos resíduos na direção y, se traçarmos contra qualquer preditor.
res=simulationOutput$scaledResiduals
```

#1ª sequência de gráficos diagnósticos:
```{r , echo = T}
# Plotando os resíduos redimensionados: Para fornecer uma ajuda visual na detecção de desvios da uniformidade na direção y, a função plot calcula uma regressão quantílica (opcional), que compara os quantis empíricos 0,25, 0,5 e 0,75 na direção y (linhas sólidas vermelhas) com os teóricos 0,25, 0,5 e 0,75 quantis (linha preta tracejada).

#Assintoticamente (ou seja, para muitos dados / resíduos), se o modelo estiver correto, os quantis teóricos e empíricos devem ser idênticos (ou seja, linhas tracejadas e sólidas devem corresponder).
```

#2ª sequência de gráficos diagnósticos:
```{r , echo = T}
# Testes formais de ajuste dos resíduos dimensionados: a função mostrará os seguintes testes
#testUniformity(), testOutliers(), testDispersion()
```

#Gráficos diagnósticos de resíduos - Modelo Predisponete (sem pesos)
```{r , echo = T}
#layout(matrix(c(1,2,3,4),nrow=2,byrow=TRUE))
testUniformity(simulationOutput)
plotResiduals(simulationOutput, rank = TRUE, quantreg = TRUE, main="Residual vs. predicted lines shoud match",
              ylab="Standardized residual", xlab="Predicted values (rank transformed)")
testDispersion(simulationOutput)
testOutliers(simulationOutput)
```

# Predisponentes método A
```{r , echo = F}
m1A=glmer(tan~p_ext_pobres_c +
            idade_mae +racacor_mae +compx +educ_mae +partos_mae +
            (1|capitais),family=binomial(link =logit), data=criamae, weights = svywght_a)
summary(m1A)
```

```{r , echo = F}
#Calculos do intervalo de confiança predisponentes método A
dados=as.data.frame(coef(summary(m1A)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)

dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança predisponentes método A
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF): Predisponentes método A - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m1A),3) # OK, VIFS menores que 5!
```

# Diagnóstico de modelos (comparação entre modelos aninhados):Predisponentes método A
```{r , echo = T}
#Modelo vazio
m0A=glmer(tan~(1|capitais),family=binomial(link = logit),data=criamae, weights = svywght_a)
logLik(m0A)
#Modelo com variáveis
logLik(m1A)
```

```{r , echo = T}
lv= -291.7681       #logLik do modelo vazio
lc= -270.3594       #logLik do modelo cheio
l=-2*(lv-lc)      #Estatística do teste l
p=  6            # numero de variáveis do cheio
q= 0             #número de variáveis do vazio
a=0.05            #nível de significância
gl=p-q            # graus de liberdade
vc=qchisq(1-a,gl) # distribuição qui-quadrado
pvalor=pchisq(l,gl,lower.tail=F)
testerv=c("Estatística l"=l,"Valor crítico:Qui-quadrado (p-q)graus de liberdade"=vc) 
```

```{r , echo = T}
c(round((testerv),2) , "p-valor" =round((pvalor),3))
# Foi significativo. Portanto, rejeita-se a H0 de que todos os coeficientes das variáveis explicativas que estão presentes APENAS no modelo cheio sejam iguais a ZERO!
```

# Diagnóstico de resíduos: Predisponentes método A - Não Puderam ser obtidos!!! Porque não é possível simular resíduos redimensionados, a partir de pesos não inteiros (como é o caso em foco)!!!

# Predisponentes método B
```{r , echo = F}
m1B=glmer(tan~p_ext_pobres_c +
            idade_mae +racacor_mae +compx +educ_mae +partos_mae +
            (1|capitais),family=binomial(link = logit),data=criamae, weights = svywght_b)
summary(m1B)
```

```{r , echo = F}
#Calculos do intervalo de confiança predisponentes método B
dados=as.data.frame(coef(summary(m1B)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)

dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança predisponentes método B
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF): Predisponentes método B - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m1B),3) # OK, VIFS menores que 5!
```

# Diagnóstico de modelos (comparação entre modelos aninhados): Predisponentes método B
```{r , echo = T}
#Modelo vazio
m0B=glmer(tan~(1|capitais),family=binomial(link = logit),data=criamae, weights = svywght_b)
logLik(m0B)
#Modelo com variáveis
logLik(m1B)
```

```{r , echo = T}
lv= -277.9366     #logLik do modelo vazio
lc= -257.4358      #logLik do modelo cheio
l=-2*(lv-lc)      #Estatística do teste l
p=  6            # numero de variáveis do cheio
q= 0             #número de variáveis do vazio
a=0.05            #nível de significância
gl=p-q            # graus de liberdade
vc=qchisq(1-a,gl) # distribuição qui-quadrado
pvalor=pchisq(l,gl,lower.tail=F)
testerv=c("Estatística l"=l,"Valor crítico:Qui-quadrado (p-q)graus de liberdade"=vc) 
```

```{r , echo = T}
c(round((testerv),2) , "p-valor" =round((pvalor),3))
# Foi significativo. Portanto, rejeita-se a H0 de que todos os coeficientes das variáveis explicativas que estão presentes APENAS no modelo cheio sejam iguais a ZERO!
```

# Diagnóstico de resíduos: Predisponentes método B - Não Puderam ser obtidos!!! Porque não é possível simular resíduos redimensionados, a partir de pesos não inteiros (como é o caso em foco)!!!

# Variáveis predisponentes significativas a p-valor < 0,2: 
```{r , echo = T}
#p_ext_pobres_c +idade_mae + racacor_mae + compax + educ_mae + partos_mae
```

## Modelos Capacitantes

# Capacitantes sem pesos

```{r , echo = F}
m2SemPesos=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c+ct_c+cnt_c+pomif_c+atiremu+esf+plano+locpre+locparto+ 
            (1|capitais),family=binomial(link = logit),data=criamae)
summary(m2SemPesos)
```

```{r , echo = F}
#Calculos do intervalo de confiança capacitantes sem pesos 
dados=as.data.frame(coef(summary(m2SemPesos)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)
dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança capacitantes sem pesos 
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF): Capacitantes sem pesos - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m2SemPesos),3) # OK, VIFS menores que 5!
```

# Diagnóstico de modelos (comparação entre modelos aninhados): Capacitantes sem pesos
```{r , echo = T}
#Modelo reduzido
logLik(m1SemPesos)
#Modelo pleno
logLik(m2SemPesos)
```

```{r , echo = T}
lr= -272.7958     #logLik do modelo reduzido
lp= -249.2352      #logLik do modelo pleno
l=-2*(lr-lp)      #Estatística do teste l
p= 15            # numero de variáveis do pleno
q= 6             #número de variáveis do reduzido
a=0.05            #nível de significância
gl=p-q            # graus de liberdade
vc=qchisq(1-a,gl) # distribuição qui-quadrado
pvalor=pchisq(l,gl,lower.tail=F)
testerv=c("Estatística l"=l,"Valor crítico:Qui-quadrado (p-q)graus de liberdade"=vc) 
```

```{r , echo = T}
c(round((testerv),2) , "p-valor" =round((pvalor),3))
# Foi significativo. Portanto, rejeita-se a H0 de que todos os coeficientes das variáveis explicativas que estão presentes APENAS no modelo cheio sejam iguais a ZERO!
```

# Diagnóstico de resíduos: Capacitantes sem pesos
```{r , echo = F}
# Criando resíduos redimensionados com alta precisão
simulationOutput <- simulateResiduals(fittedModel = m2SemPesos, n = 1000)

# Guardando os rediduos obtidos: Como discutido acima, para um modelo especificado corretamente, esperaríamos uma distribuição uniforme (plana) dos resíduos na direção y, se traçarmos contra qualquer preditor.
res=simulationOutput$scaledResiduals
```

#1ª sequência de gráficos diagnósticos:
```{r , echo = T}
# Plotando os resíduos redimensionados: Para fornecer uma ajuda visual na detecção de desvios da uniformidade na direção y, a função plot calcula uma regressão quantílica (opcional), que compara os quantis empíricos 0,25, 0,5 e 0,75 na direção y (linhas sólidas vermelhas) com os teóricos 0,25, 0,5 e 0,75 quantis (linha preta tracejada).

#Assintoticamente (ou seja, para muitos dados / resíduos), se o modelo estiver correto, os quantis teóricos e empíricos devem ser idênticos (ou seja, linhas tracejadas e sólidas devem corresponder).
```

#2ª sequência de gráficos diagnósticos:
```{r , echo = T}
# Testes formais de ajuste dos resíduos dimensionados: a função mostrará os seguintes testes
#testUniformity(), testOutliers(), testDispersion()
```

#Gráficos diagnósticos de resíduos - Modelo Capacitante (sem pesos)
```{r , echo = T}
#layout(matrix(c(1,2,3,4),nrow=2,byrow=TRUE))
testUniformity(simulationOutput)
plotResiduals(simulationOutput, rank = TRUE, quantreg = TRUE, main="Residual vs. predicted lines shoud match",
              ylab="Standardized residual", xlab="Predicted values (rank transformed)")
testDispersion(simulationOutput)
testOutliers(simulationOutput)
```


# Capacitantes método A
```{r , echo = F}
m2A=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c+ct_c+cnt_c+pomif_c+atiremu +esf +plano +locpre+locparto+ 
            (1|capitais),family=binomial(link =logit), data=criamae, weights = svywght_a)
summary(m2A)
```

```{r , echo = F}
#Calculos do intervalo de confiança capacitantes método A
dados=as.data.frame(coef(summary(m2A)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)
dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança capacitantes método A
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF): Capacitantes método A - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m2A),3) # OK, VIFS menores que 5!
```

# Diagnóstico de modelos (comparação entre modelos aninhados): Capacitantes método A
```{r , echo = T}
#Modelo reduzido
logLik(m1A)
#Modelo pleno
logLik(m2A)
```

```{r , echo = T}
lr=  -270.3594      #logLik do modelo reduzido
lp= -245.0073      #logLik do modelo pleno
l=-2*(lr-lp)      #Estatística do teste l
p= 15            # numero de variáveis do pleno
q= 6             #número de variáveis do reduzido
a=0.05            #nível de significância
gl=p-q            # graus de liberdade
vc=qchisq(1-a,gl) # distribuição qui-quadrado
pvalor=pchisq(l,gl,lower.tail=F)
testerv=c("Estatística l"=l,"Valor crítico:Qui-quadrado (p-q)graus de liberdade"=vc) 
```

```{r , echo = T}
c(round((testerv),2) , "p-valor" =round((pvalor),3))
# Foi significativo. Portanto, rejeita-se a H0 de que todos os coeficientes das variáveis explicativas que estão presentes APENAS no modelo cheio sejam iguais a ZERO!
```

# Diagnóstico de resíduos: Capacitantes método A - Não Puderam ser obtidos!!! Porque não é possível simular resíduos redimensionados, a partir de pesos não inteiros (como é o caso em foco)!!!

# Capacitantes método B
```{r , echo = F}
m2B=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c+ct_c+cnt_c+pomif_c +atiremu +esf +plano +locpre +locparto+
            (1|capitais),family=binomial(link = logit),data=criamae, weights = svywght_b)
summary(m2B)
```

```{r , echo = F}
#Calculos do intervalo de confiança capacitantes método B
dados=as.data.frame(coef(summary(m2B)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)
dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança capacitantes método B
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF): Capacitantes método B - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m2B),3) # OK, VIFS menores que 5!
```

# Diagnóstico de modelos (comparação entre modelos aninhados): Capacitantes método B
```{r , echo = T}
#Modelo reduzido
logLik(m1B)
#Modelo pleno
logLik(m2B)
```

```{r , echo = T}
lr= -257.4358     #logLik do modelo reduzido
lp= -232.5788     #logLik do modelo pleno
l=-2*(lr-lp)      #Estatística do teste l
p= 15            # numero de variáveis do pleno
q= 6             #número de variáveis do reduzido
a=0.05            #nível de significância
gl=p-q            # graus de liberdade
vc=qchisq(1-a,gl) # distribuição qui-quadrado
pvalor=pchisq(l,gl,lower.tail=F)
testerv=c("Estatística l"=l,"Valor crítico:Qui-quadrado (p-q)graus de liberdade"=vc) 
```

```{r , echo = T}
c(round((testerv),2) , "p-valor" =round((pvalor),3))
# Foi significativo. Portanto, rejeita-se a H0 de que todos os coeficientes das variáveis explicativas que estão presentes APENAS no modelo cheio sejam iguais a ZERO!
```

# Diagnóstico de resíduos: Capacitantes método B - Não Puderam ser obtidos!!! Porque não é possível simular resíduos redimensionados, a partir de pesos não inteiros (como é o caso em foco)!!!

# Variáveis capacitantes significativas a p-valor < 0,2: 
```{r , echo = T}
#c7_c +ct_c +plano +locpre 
```

## Modelos de Necessidade

# Necessidade sem pesos
```{r , echo = F}
m3SemPesos=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c +ct_c +plano +locpre +
            taxami_c + taxasc_c + 
            (1|capitais),family=binomial(link = logit),data=criamae)
summary(m3SemPesos)
```

```{r , echo = F}
#Calculos do intervalo de confiança de necessidade sem pesos
dados=as.data.frame(coef(summary(m3SemPesos)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)
dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança necessidade sem pesos
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF):Necessidade sem pesos - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m3SemPesos),3) # OK, VIFS menores que 5! Porém surge um aviso a respeito da matriz de variâncias-covariÂncias dizendo que não foram positivamente definidas ou contém valores NAs!
```

# Diagnóstico de resíduos: Necessidade sem pesos
```{r , echo = F}
# Criando resíduos redimensionados com alta precisão
simulationOutput <- simulateResiduals(fittedModel = m3SemPesos, n = 1000)

# Guardando os rediduos obtidos: Como discutido acima, para um modelo especificado corretamente, esperaríamos uma distribuição uniforme (plana) dos resíduos na direção y, se traçarmos contra qualquer preditor.
res=simulationOutput$scaledResiduals
```

#1ª sequência de gráficos diagnósticos:
```{r , echo = T}
# Plotando os resíduos redimensionados: Para fornecer uma ajuda visual na detecção de desvios da uniformidade na direção y, a função plot calcula uma regressão quantílica (opcional), que compara os quantis empíricos 0,25, 0,5 e 0,75 na direção y (linhas sólidas vermelhas) com os teóricos 0,25, 0,5 e 0,75 quantis (linha preta tracejada).

#Assintoticamente (ou seja, para muitos dados / resíduos), se o modelo estiver correto, os quantis teóricos e empíricos devem ser idênticos (ou seja, linhas tracejadas e sólidas devem corresponder).
```

#2ª sequência de gráficos diagnósticos:
```{r , echo = T}
# Testes formais de ajuste dos resíduos dimensionados: a função mostrará os seguintes testes
#testUniformity(), testOutliers(), testDispersion()
```

#Gráficos diagnósticos de resíduos - Modelo Necessidade (sem pesos)
```{r , echo = T}
#layout(matrix(c(1,2,3,4),nrow=2,byrow=TRUE))
testUniformity(simulationOutput)
plotResiduals(simulationOutput, rank = TRUE, quantreg = TRUE, main="Residual vs. predicted lines shoud match",
              ylab="Standardized residual", xlab="Predicted values (rank transformed)")
testDispersion(simulationOutput)
testOutliers(simulationOutput)
```

# Necessidade método A
```{r , echo = F}
m3A=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c +ct_c +plano +locpre +
            taxami_c + taxasc_c + 
            (1|capitais),family=binomial(link =logit), data=criamae, weights = svywght_a)
summary(m3A)
```

```{r , echo = F}
#Calculos do intervalo de confiança de necessidade método A 
dados=as.data.frame(coef(summary(m3A)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)
dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança necessidade método A
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF): Necessidade método A - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m3A),3) # OK, VIFS menores que 5!Porém surge um aviso a respeito da matriz de variâncias-covariÂncias dizendo que não foram positivamente definidas ou contém valores NAs!
```

# Diagnóstico de resíduos: Necessidade método A - Não Puderam ser obtidos!!! Porque não é possível simular resíduos redimensionados, a partir de pesos não inteiros (como é o caso em foco)!!!

# Necessidade método B
```{r , echo = F}
m3B=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c +ct_c +plano +locpre +
            taxami_c + taxasc_c +
            (1|capitais),family=binomial(link = logit),data=criamae, weights = svywght_b)
summary(m3B)
```

```{r , echo = F}
#Calculos do intervalo de confiança de necessidade método B 
dados=as.data.frame(coef(summary(m3A)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)
dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança necessidade método B
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF): Necessidade método B - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m3B),3) # OK, VIFS menores que 5!Porém surge um aviso a respeito da matriz de variâncias-covariÂncias dizendo que não foram positivamente definidas ou contém valores NAs!
```

# Diagnóstico de resíduos: Necessidade método B - Não Puderam ser obtidos!!! Porque não é possível simular resíduos redimensionados, a partir de pesos não inteiros (como é o caso em foco)!!!

# Variáveis de necessidade significativas a p-valor < 0,2: 
```{r , echo = T}
# Nenhuma variável de necessidade se mostrou significativa a p-valor < 0,2
```

## Modelos de Comportamentos em Saúde


# Comportamentos em Saúde sem pesos
```{r , echo = F}
m4SemPesos=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c +ct_c +plano +locpre + 
            consultas7 + risco + sifilis + hiv + 
            (1|capitais),family=binomial(link = logit),data=criamae)
summary(m4SemPesos)
```

```{r , echo = F}
#Calculos do intervalo de confiança comportamentos em Saúde sem pesos
dados=as.data.frame(coef(summary(m4SemPesos)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)
dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança comportamentos em Saúde sem pesos
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF): Comportamentos em Saúde sem pesos - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m4SemPesos),3) # OK, VIFS menores que 5!
```

# Diagnóstico de modelos (comparação entre modelos aninhados): Comportamentos em Saúde sem pesos
```{r , echo = T}
#Modelo reduzido
logLik(m2SemPesos)
#Modelo pleno
logLik(m4SemPesos)
```

```{r , echo = T}
lr= -249.2352      #logLik do modelo reduzido
lp= -244.666      #logLik do modelo pleno
l=-2*(lr-lp)      #Estatística do teste l
p= 14            # numero de variáveis do pleno
q= 14             #número de variáveis do reduzido
a=0.05            #nível de significância
gl=p-q            # graus de liberdade
vc=qchisq(1-a,gl) # distribuição qui-quadrado
pvalor=pchisq(l,gl,lower.tail=F)
testerv=c("Estatística l"=l,"Valor crítico:Qui-quadrado (p-q)graus de liberdade"=vc) 
```

```{r , echo = T}
c(round((testerv),2) , "p-valor" =round((pvalor),3))
# Foi significativo. Portanto, rejeita-se a H0 de que todos os coeficientes das variáveis explicativas que estão presentes APENAS no modelo cheio sejam iguais a ZERO!
```

# Diagnóstico de resíduos: Comportamentos sem pesos
```{r , echo = F}
# Criando resíduos redimensionados com alta precisão
simulationOutput <- simulateResiduals(fittedModel = m4SemPesos, n = 1000)

# Guardando os rediduos obtidos: Como discutido acima, para um modelo especificado corretamente, esperaríamos uma distribuição uniforme (plana) dos resíduos na direção y, se traçarmos contra qualquer preditor.
res=simulationOutput$scaledResiduals
```

#1ª sequência de gráficos diagnósticos:
```{r , echo = T}
# Plotando os resíduos redimensionados: Para fornecer uma ajuda visual na detecção de desvios da uniformidade na direção y, a função plot calcula uma regressão quantílica (opcional), que compara os quantis empíricos 0,25, 0,5 e 0,75 na direção y (linhas sólidas vermelhas) com os teóricos 0,25, 0,5 e 0,75 quantis (linha preta tracejada).

#Assintoticamente (ou seja, para muitos dados / resíduos), se o modelo estiver correto, os quantis teóricos e empíricos devem ser idênticos (ou seja, linhas tracejadas e sólidas devem corresponder).
```

#2ª sequência de gráficos diagnósticos:
```{r , echo = T}
# Testes formais de ajuste dos resíduos dimensionados: a função mostrará os seguintes testes
#testUniformity(), testOutliers(), testDispersion()
```

#Gráficos diagnósticos de resíduos - Modelo Comportamentos (sem pesos)
```{r , echo = T}
#layout(matrix(c(1,2,3,4),nrow=2,byrow=TRUE))
testUniformity(simulationOutput)
plotResiduals(simulationOutput, rank = TRUE, quantreg = TRUE, main="Residual vs. predicted lines shoud match",
              ylab="Standardized residual", xlab="Predicted values (rank transformed)")
testDispersion(simulationOutput)
testOutliers(simulationOutput)
```


# Comportamentos em Saúde método A
```{r , echo = F}
m4A=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c +ct_c +plano +locpre +
            consultas7 + risco + sifilis + hiv +
            (1|capitais),family=binomial(link =logit), data=criamae, weights = svywght_a)
summary(m4A)
```

```{r , echo = F}
#Calculos do intervalo de confiança comportamentos em Saúde método B
dados=as.data.frame(coef(summary(m4A)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)
dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança comportamentos em Saúde método A
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF): Comportamentos em Saúde método A - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m4A),3) # OK, VIFS menores que 5!
```

# Diagnóstico de modelos (comparação entre modelos aninhados): Comportamentos em Saúde método A
```{r , echo = T}
#Modelo reduzido
logLik(m2A)
#Modelo pleno
logLik(m4A)
```

```{r , echo = T}
lr= -245.0073      #logLik do modelo reduzido
lp= -240.1273       #logLik do modelo pleno
l=-2*(lr-lp)      #Estatística do teste l
p= 14            # numero de variáveis do pleno
q= 14             #número de variáveis do reduzido
a=0.05            #nível de significância
gl=p-q            # graus de liberdade
vc=qchisq(1-a,gl) # distribuição qui-quadrado
pvalor=pchisq(l,gl,lower.tail=F)
testerv=c("Estatística l"=l,"Valor crítico:Qui-quadrado (p-q)graus de liberdade"=vc) 
```

```{r , echo = T}
c(round((testerv),2) , "p-valor" =round((pvalor),3))
# Foi significativo. Portanto, rejeita-se a H0 de que todos os coeficientes das variáveis explicativas que estão presentes APENAS no modelo cheio sejam iguais a ZERO!
```

# Diagnóstico de resíduos: Comportamentos método A - Não Puderam ser obtidos!!! Porque não é possível simular resíduos redimensionados, a partir de pesos não inteiros (como é o caso em foco)!!!

# Comportamentos em Saúde método B
```{r , echo = F}
m4B=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c +ct_c +plano +locpre +
            consultas7 + risco + sifilis + hiv +
            (1|capitais),family=binomial(link = logit),data=criamae, weights = svywght_b)
summary(m4B)
```

```{r , echo = F}
#Calculos do intervalo de confiança comportamentos em Saúde método B
dados=as.data.frame(coef(summary(m4B)))
colnames(dados)=c("beta","epbeta","zvalue","pvalor")
dados$razaodechances=(exp(dados$beta))

attach(dados)
logrc=dados$beta
ep=dados$epbeta 
z=qnorm(1-0.05/2)
logli=logrc-z*ep
logls=logrc+z*ep

dados$linf=exp(logli)
dados$lsup=exp(logls)
dados$razaodechances=round(dados$razaodechances,2)
dados$linf=round(dados$linf,2)
dados$lsup=round(dados$lsup,2)
dados$pvalor=round(dados$pvalor,3)
```

```{r , echo = T}
# Intervalos de confiança comportamentos em Saúde método B
subset(dados, select=c(razaodechances,linf,lsup,pvalor))
detach(dados)
```

# Diagnóstico de modelos (VIF): Comportamentos em Saúde método B - Verificando a assunção de "não-multicolinearidade" das variáveis preditoras ou independentes
```{r , echo = T}
round(vif(m4B),3) # OK, VIFS menores que 5!
```

# Diagnóstico de modelos (comparação entre modelos aninhados): Comportamentos em Saúde método B
```{r , echo = T}
#Modelo reduzido
logLik(m2B)
#Modelo pleno
logLik(m4B)
```


```{r , echo = T}
lr= -232.5788    #logLik do modelo reduzido
lp= -227.8333       #logLik do modelo pleno
l=-2*(lr-lp)      #Estatística do teste l
p= 14            # numero de variáveis do pleno
q= 14             #número de variáveis do reduzido
a=0.05            #nível de significância
gl=p-q            # graus de liberdade
vc=qchisq(1-a,gl) # distribuição qui-quadrado
pvalor=pchisq(l,gl,lower.tail=F)
testerv=c("Estatística l"=l,"Valor crítico:Qui-quadrado (p-q)graus de liberdade"=vc) 
```

```{r , echo = T}
c(round((testerv),2) , "p-valor" =round((pvalor),3))
# Foi significativo. Portanto, rejeita-se a H0 de que todos os coeficientes das variáveis explicativas que estão presentes APENAS no modelo cheio sejam iguais a ZERO!
```

# Diagnóstico de resíduos: Comportamentos método B - Não Puderam ser obtidos!!! Porque não é possível simular resíduos redimensionados, a partir de pesos não inteiros (como é o caso em foco)!!!


# Variáveis de Comportamentos em Saúde significativas a p-valor < 0,2: 
```{r , echo = T}
# consultas7
```

## VPC (Variance partition coefficient ~ Coeficiente de partição de variância)

## VPC -> Com base no modelo de comportamentos - foram construídos modelos para o cálculo do VPC,  elencando apenas as variáveis que foram significativas para a construção de 2 perfis: Baixa e alta probabilidade de uso da TAN (abordagem por simulação)

```{r , echo = T}
# Modelo especial para o cálculo do VPC - sem pesos
m5SemPesos=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c +ct_c +plano +locpre + 
            consultas7 +  
            (1|capitais),family=binomial(link = logit),data=criamae)
summary(m5SemPesos)
```

# Baixa probabilidade de uso: 
```{r, echo = T}
#p_ext_pobres_c:0 (média)
#idade: 45-49 anos
#raça/cor: parda
#Companheirx:sim
#Escolaridade:fundamental/ médio incompleto
#Número de partos:2 partos
#c7_c:0 (média)
#ct_c: 0 (média)
#plano: não
#locpre: público
#número de consultas de pré-natal: menos de 7 
```

```{r, echo = T}
fcoef = fixef(m5SemPesos)

# Second Profile
perf1 = c(1,0,0,0,0,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,0) # PERFIL
rcoef = VarCorr(m5SemPesos) 

# Step 1
set.seed(1)
nvar = rnorm(5000, 0, sqrt(0.1291)) # uoj

# Step 2
parc1 = sum(fcoef*perf1)

pl1 = parc1 + nvar
pi_j = exp(pl1)/(1+exp(pl1)) 
v1j = pi_j*(1-pi_j) 

# Step 3
vn1 = mean(v1j)
vn2 = var(pi_j)

vpc = vn2 / (vn1+vn2)

vn1; vn2; vpc

resultado=vpc*100
```

```{r , echo = T}
#Coeficiente de partição de variância para baixa probabilidade de uso (%)
round(resultado,2)
```

# Alta probabilidade de uso
```{r, echo = T}
#p_ext_pobres_c:0 (média)
#idade: 35-39 anos
#raça/cor: branca
#Companheirx:não
#Escolaridade:Superior completo
#Número de partos: 1 parto
#c7_c:0 (média)
#ct_c: 0 (média)
#plano: sim
#locpre: privado
#número de consultas de pré-natal: mais de 7 
```

```{r, echo = T}
fcoef = fixef(m5SemPesos)

# First Profile
perf1 = c(1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,1,1,1) # PERFIL
rcoef = VarCorr(m5SemPesos) 

# Step 1
set.seed(1)
nvar = rnorm(5000, 0, sqrt(0.1291)) # uoj

# Step 2
parc1 = sum(fcoef*perf1)

pl1 = parc1 + nvar
pi_j = exp(pl1)/(1+exp(pl1)) 
v1j = pi_j*(1-pi_j) 

# Step 3
vn1 = mean(v1j)
vn2 = var(pi_j)

vpc = vn2 / (vn1+vn2)

vn1; vn2; vpc

resultado=vpc*100
```

```{r , echo = T}
#Coeficiente de partição de variância para alta probabilidade de uso (%)
round(resultado,2)
```

## VPC ->  Com base no modelo de comportamentos método A - elencando apenas as variáveis que foram importantes para a construção de 2 perfis: Baixa e alta probabilidade de uso da TAN (abordagem por simulação)

```{r , echo = T}
# Modelo especial para o cálculo do VPC - método A
m5A=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c +ct_c +plano +locpre +
            consultas7 +
            (1|capitais),family=binomial(link =logit), data=criamae, weights = svywght_a)
summary(m5A)
```

## Baixa probabilidade de uso
```{r, echo = T}
fcoef = fixef(m5A)

# Second  Profile
perf1 = c(1,0,0,0,0,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,0) # PERFIL
rcoef = VarCorr(m5A) 

# Step 1
set.seed(1)
nvar = rnorm(5000, 0, sqrt(0.1349)) # uoj

# Step 2
parc1 = sum(fcoef*perf1)

pl1 = parc1 + nvar
pi_j = exp(pl1)/(1+exp(pl1)) 
v1j = pi_j*(1-pi_j) 

# Step 3
vn1 = mean(v1j)
vn2 = var(pi_j)

vpc = vn2 / (vn1+vn2)

vn1; vn2; vpc

resultado=vpc*100
```

```{r , echo = T}
#Coeficiente de partição de variância para baixa probabilidade de uso (%)
round(resultado,2)
```

## Alta probabilidade de uso

```{r, echo = T}
fcoef = fixef(m5A)

# First Profile
perf1 = c(1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,1) # PERFIL
rcoef = VarCorr(m5A) 

# Step 1
set.seed(1)
nvar = rnorm(5000, 0, sqrt(0.1349)) # uoj

# Step 2
parc1 = sum(fcoef*perf1)

pl1 = parc1 + nvar
pi_j = exp(pl1)/(1+exp(pl1)) 
v1j = pi_j*(1-pi_j) 

# Step 3
vn1 = mean(v1j)
vn2 = var(pi_j)

vpc = vn2 / (vn1+vn2)

vn1; vn2; vpc

resultado=vpc*100
```

```{r , echo = T}
#Coeficiente de partição de variância para alta probabilidade de uso (%)
round(resultado,2)
```

## VPC ->  Com base no modelo de comportamentos método B - elencando apenas as variáveis que foram importantes para a construção de 2 perfis: Baixa e alta probabilidade de uso da TAN (abordagem por simulação)

```{r , echo = T}
# Modelo especial para o cálculo do VPC - método B
m5B=glmer(tan~ p_ext_pobres_c + idade_mae + racacor_mae + compx + educ_mae + partos_mae +
            c7_c +ct_c +plano +locpre +
            consultas7 +
            (1|capitais),family=binomial(link = logit),data=criamae, weights = svywght_b)
summary(m5B)
```

## Baixa probabilidade de uso
```{r, echo = T}

fcoef = fixef(m5B)

# Second  Profile
perf1 = c(1,0,0,0,0,0,1,0,0,1,1,0,0,0,1,0,0,0,0,0,0) # PERFIL
rcoef = VarCorr(m5B) 

# Step 1
set.seed(1)
nvar = rnorm(5000, 0, sqrt(0.1095)) # uoj

# Step 2
parc1 = sum(fcoef*perf1)

pl1 = parc1 + nvar
pi_j = exp(pl1)/(1+exp(pl1)) 
v1j = pi_j*(1-pi_j) 

# Step 3
vn1 = mean(v1j)
vn2 = var(pi_j)

vpc = vn2 / (vn1+vn2)

vn1; vn2; vpc

resultado=vpc*100
```

```{r , echo = T}
#Coeficiente de partição de variância para baixa probabilidade de uso (%)
round(resultado,2)
```

## Alta probabilidade de uso

```{r, echo = T}
fcoef = fixef(m5B)

# First Profile
perf1 = c(1,0,0,0,1,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,1) # PERFIL
rcoef = VarCorr(m5B) 

# Step 1
set.seed(1)
nvar = rnorm(5000, 0, sqrt(0.1095)) # uoj

# Step 2
parc1 = sum(fcoef*perf1)

pl1 = parc1 + nvar
pi_j = exp(pl1)/(1+exp(pl1)) 
v1j = pi_j*(1-pi_j) 

# Step 3
vn1 = mean(v1j)
vn2 = var(pi_j)

vpc = vn2 / (vn1+vn2)

vn1; vn2; vpc

resultado=vpc*100
```

```{r , echo = T}
#Coeficiente de partição de variância para alta probabilidade de uso (%)
round(resultado,2)
```

## VPC ->  Abordagem via modelo de limite linear -  sem pesos 
```{r , echo = F}
#Modelo vazio
m0SemPesos=glmer(tan~(1|capitais),family=binomial(link = logit),data=criamae)
summary(m0SemPesos)
vpc_l=sqrt(0.8392)/(sqrt(0.8392)+3.29)
```

```{r , echo = T}
#Coeficiente de partição de variância (abordagem via modelo de limite linear)
vpc_l
#VPC (%)
round(vpc_l*100,2)
```

## VPC -> Abordagem via modelo de limite linear -  método A 
```{r , echo = F}
#Modelo vazio
m0A=glmer(tan~(1|capitais),family=binomial(link = logit),data=criamae, weights = svywght_a)
summary(m0A)
vpc_l=sqrt(0.9398)/(sqrt(0.9398)+3.29)
```

```{r , echo = T}
#Coeficiente de partição de variância (abordagem via modelo de limite linear)
vpc_l
#VPC (%)
round(vpc_l*100,2)
```


## VPC -> Modelo predisponentes método B (abordagem via modelo de limite linear)
```{r , echo = F}
#Modelo vazio
m0B=glmer(tan~(1|capitais),family=binomial(link = logit),data=criamae, weights = svywght_b)
summary(m0B)
vpc_l=sqrt(0.8999)/(sqrt(0.8999)+3.29)
```

```{r , echo = T}
#Coeficiente de partição de variância (abordagem via modelo de limite linear)
vpc_l
#VPC (%)
round(vpc_l*100,2)
```

## Imprimindo todas as variâncias (erros padrão) e AICs dos modelos obtidos
```{r , echo = T}
#Predisponentes
vc <- VarCorr(m1SemPesos) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m1SemPesos),2)

vc <- VarCorr(m1A) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m1A),2)

vc <- VarCorr(m1B) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m1B),2)

#Capacitantes
vc <- VarCorr(m2SemPesos) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m2SemPesos),2)

vc <- VarCorr(m2A) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m2A),2)

vc <- VarCorr(m2B) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m2B),2)

#Necessidade
vc <- VarCorr(m3SemPesos) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m3SemPesos),2)

vc <- VarCorr(m3A) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m3A),2)

vc <- VarCorr(m3B) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m3B),2)

#Comportamentos
vc <- VarCorr(m4SemPesos) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m4SemPesos),2)

vc <- VarCorr(m4A) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m4A),2)

vc <- VarCorr(m4B) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m4B),2)

#Modelo VPC - 
vc <- VarCorr(m5SemPesos) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m5SemPesos),2)

vc <- VarCorr(m5A) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m5A),2)

vc <- VarCorr(m5B) 
print(vc,comp=c("Variance","Std.Dev."),digits=2)
round(AIC(m5B),2)

```

